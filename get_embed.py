"""
Generate embeddings for landmark names
"""
import os
import argparse
import json
from pathlib import Path
import openai

from gpt3 import GPT3
from utils import load_from_file, save_to_file

openai.api_key = os.getenv("OPENAI_API_KEY")


def load_names(fpath):
    """
    Load names of known objects in given environment.
    Assume 1 name per line in txt file, e.g. data/osm/osm_landmarks_corlw.txt
    Assume 1 dictionary of key: landmark name, value: semantic info in json file, e.g. data/osm/lmks/boston.json
    """
    ftype = os.path.splitext(fpath)[-1][1:]
    if ftype == "txt":
        with open(fpath, 'r') as rf:
            names = [line.strip() for line in rf.readlines()]
    else:
        raise ValueError(f"ERROR: file type {ftype} not recognized")
    return names


def store_embeds(model, lmk_path, keep_keys, gpt3_embed_engine=None):
    lmk2sem = load_from_file(lmk_path)

    if model == "gpt3":
        ground_module = GPT3(gpt3_embed_engine)
    # elif model == 'bert':
    #     ground_module = BERT()
    else:
        raise ValueError("ERROR: grounding module not recognized")

    name2embed = {}
    for lmk, sem in lmk2sem.items():
        sem_filtered = {"name": lmk}
        sem_filtered.update({k: v for k, v in sem.items() if k in keep_keys})
        name2embed[lmk] = ground_module.get_embedding(json.dumps(sem_filtered))

    lmk_fname = Path(lmk_path).stem
    if model == "gpt3":
        save_fpath = f"data/osm/lmk_embeds/obj2embed_{lmk_fname}_{gpt3_embed_engine}.pkl"
    else:
        save_fpath = f"data/osm/lmk_embeds/obj2embed_{lmk_fname}_{model}.pkl"
    save_to_file(name2embed, save_fpath)
    return save_fpath


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--lmk_path", type=str, default="data/osm/lmks", help="fpath or dpath to lmks.")
    parser.add_argument("--model", type=str, default="gpt3", choices=["gpt3", "bert"])
    parser.add_argument("--gpt3_embed_engine", type=str, default="text-embedding-ada-002")
    args = parser.parse_args()

    if os.path.isdir(args.lmk_path):
        lmk_paths = [os.path.join(args.lmk_path, fname) for fname in os.listdir(args.lmk_path) if "json" in fname]
    else:
        lmk_paths = [args.lmk_path]

    keep_keys = [
        "amenity", "shop", "addr:street",
        "short_name", "building", "building:part" "leisure", "tourism", "historic",
        "healthcare", "area", "landuse", "waterway", "aeroway", "highway", "office", "operator", "brand", "branch",
        "cuisine", "beauty", "official_name", "alt_name", "station", "railway", "subway",
    ]
    for idx, lmk_path in enumerate(lmk_paths):
        print(f"generating landmark embedding for {Path(lmk_path).stem}")
        save_fpath = store_embeds(args.model, lmk_path, keep_keys, args.gpt3_embed_engine)
        print(f"{idx}: embeddings generated by {args.model} model, stored at {save_fpath}")

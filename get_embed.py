"""
Generate embeddings for landmark names
"""
import os
import argparse
import json
from pathlib import Path
import openai

from gpt import GPT3
from utils import load_from_file, save_to_file

openai.api_key = os.getenv("OPENAI_API_KEY")


def load_names(fpath):
    """
    Load names of known objects in given environment.
    Assume 1 name per line in txt file, e.g. data/osm/osm_landmarks_corlw.txt
    Assume 1 dictionary of key: landmark name, value: semantic info in json file, e.g. data/osm/lmks/boston.json
    """
    ftype = os.path.splitext(fpath)[-1][1:]
    if ftype == "txt":
        with open(fpath, 'r') as rf:
            names = [line.strip() for line in rf.readlines()]
    else:
        raise ValueError(f"ERROR: file type {ftype} not recognized")
    return names


def generate_embeds(embed_model, save_dpath, lmk2sem, keep_keys=(), embed_engine=None, exp_name="lang2ltl-api", update_embed=False):
    """
    Generate a database of known landmarks and their embeddings.
    :param embed_model: model used to generate embeddings.
    :param save_dpath: folder to save generated embeddings.
    :param lmk2sem: known landmarks and their semantic information in dict or file.
    :param keep_keys: filter semantic information of landmarks used to construct embeddings.
    :param embed_engine: embedding engine to use with embedding model , e.g., text-embedding-ada-002
    :param exp_name: experiment ID used in file name.
    :param update_embed: if to append new embeddings to existing embeddings, and overwrite if same landmark name.
    """
    lmk2sem = load_from_file(lmk2sem) if isinstance(lmk2sem, str) else lmk2sem

    if embed_model == "gpt3":
        ground_module = GPT3(embed_engine)
    else:
        raise ValueError("ERROR: grounding module not recognized")

    name2embed = {}
    for lmk, sem in lmk2sem.items():
        sem_filtered = {"name": lmk}
        if keep_keys:
            sem_filtered.update({k: v for k, v in sem.items() if k in keep_keys})
        name2embed[lmk] = ground_module.get_embedding(json.dumps(sem_filtered))

    embed_dpath = os.path.join(save_dpath, "lmk_sem_embeds")
    os.makedirs(embed_dpath, exist_ok=True)
    lmk_fname = Path(lmk2sem).stem if isinstance(lmk2sem, str) else exp_name
    if embed_model == "gpt3":
        save_fpath = os.path.join(embed_dpath, f"obj2embed_{lmk_fname}_{embed_model}-{embed_engine}.pkl")
    else:
        save_fpath = os.path.join(embed_dpath, f"obj2embed_{lmk_fname}_{embed_model}.pkl")

    if os.path.isfile(save_fpath):
        name2embed_exist = load_from_file(save_fpath)
        if update_embed:
            name2embed = {**name2embed_exist, **name2embed}

    save_to_file(name2embed, save_fpath)
    return name2embed, save_fpath


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--env", type=str, default="cleanup", choices=["osm", "cleanup"], help="fpath or dpath to lmks.")
    parser.add_argument("--model", type=str, default="gpt3", choices=["gpt3", "llama"])
    parser.add_argument("--gpt3_embed_engine", type=str, default="text-embedding-ada-002")
    args = parser.parse_args()

    env_dpath = os.path.join("data", args.env)
    lmk_dpath = os.path.join(env_dpath, "lmks")
    lmk_fpaths = [os.path.join(lmk_dpath, fname) for fname in os.listdir(lmk_dpath) if "json" in fname]

    keep_keys = [
        "amenity", "shop", "addr:street",
        "short_name", "building", "building:part" "leisure", "tourism", "historic",
        "healthcare", "area", "landuse", "waterway", "aeroway", "highway", "office", "operator", "brand", "branch",
        "cuisine", "beauty", "official_name", "alt_name", "station", "railway", "subway",
    ] if args.env == "osm" else []
    for idx, lmk_fpath in enumerate(lmk_fpaths):
        print(f"generating landmark embedding for {lmk_fpath}")
        _, save_fpath = generate_embeds(args.model, env_dpath, lmk_fpath, keep_keys, args.gpt3_embed_engine)
        print(f"{idx}: embeddings generated by model: {args.model}\nstored at: {save_fpath}\n")

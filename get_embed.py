"""
Generate embeddings for landmark names
"""
import os
import argparse
import json
from pathlib import Path
import openai

from gpt3 import GPT3
from utils import load_from_file, save_to_file

openai.api_key = os.getenv("OPENAI_API_KEY")


def load_names(fpath):
    """
    Load names of known objects in given environment.
    Assume 1 name per line in txt file, e.g. data/osm/osm_landmarks_corlw.txt
    Assume 1 dictionary of key: landmark name, value: semantic info in json file, e.g. data/osm/lmks/boston.json
    """
    ftype = os.path.splitext(fpath)[-1][1:]
    if ftype == "txt":
        with open(fpath, 'r') as rf:
            names = [line.strip() for line in rf.readlines()]
    else:
        raise ValueError(f"ERROR: file type {ftype} not recognized")
    return names


def store_embeds(model, save_dpath, lmks, keep_keys, gpt3_embed_engine=None, update_embed=False):
    embed_dpath = os.path.join(save_dpath, "lmk_sem_embeds")
    os.makedirs(embed_dpath, exist_ok=True)
    lmk_fname = Path(lmks).stem if isinstance(lmks, str) else "lang2ltl_api"
    if model == "gpt3":
        save_fpath = os.path.join(embed_dpath, f"obj2embed_{lmk_fname}_{gpt3_embed_engine}.pkl")
    else:
        save_fpath = os.path.join(embed_dpath, f"obj2embed_{lmk_fname}_{model}.pkl")

    if not os.path.isfile(save_fpath) or update_embed:
        lmk2sem = load_from_file(lmks) if isinstance(lmks, str) else lmks

        if model == "gpt3":
            ground_module = GPT3(gpt3_embed_engine)
        # elif model == 'bert':
        #     ground_module = BERT()
        else:
            raise ValueError("ERROR: grounding module not recognized")

        name2embed = {}
        for lmk, sem in lmk2sem.items():
            sem_filtered = {"name": lmk}
            if keep_keys:
                sem_filtered.update({k: v for k, v in sem.items() if k in keep_keys})
            name2embed[lmk] = ground_module.get_embedding(json.dumps(sem_filtered))

        save_to_file(name2embed, save_fpath)
    else:
        name2embed = load_from_file(save_fpath)

    return save_fpath, name2embed


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--env", type=str, default="cleanup", choices=["osm", "cleanup"], help="fpath or dpath to lmks.")
    parser.add_argument("--model", type=str, default="gpt3", choices=["gpt3", "bert"])
    parser.add_argument("--gpt3_embed_engine", type=str, default="text-embedding-ada-002")
    args = parser.parse_args()

    env_dpath = os.path.join("data", args.env)
    lmk_dpath = os.path.join(env_dpath, "lmks")
    lmk_fpaths = [os.path.join(lmk_dpath, fname) for fname in os.listdir(lmk_dpath) if "json" in fname]

    keep_keys = [
        "amenity", "shop", "addr:street",
        "short_name", "building", "building:part" "leisure", "tourism", "historic",
        "healthcare", "area", "landuse", "waterway", "aeroway", "highway", "office", "operator", "brand", "branch",
        "cuisine", "beauty", "official_name", "alt_name", "station", "railway", "subway",
    ] if args.env == "osm" else []
    for idx, lmk_fpath in enumerate(lmk_fpaths):
        print(f"generating landmark embedding for {lmk_fpath}")
        save_fpath, _ = store_embeds(args.model, env_dpath, lmk_fpath, keep_keys, args.gpt3_embed_engine)
        print(f"{idx}: embeddings generated by model: {args.model}\nstored at: {save_fpath}\n")

"""
Generate embeddings for landmark names
"""
import os
import argparse
import json
from pathlib import Path
import openai

from gpt3 import GPT3
from utils import load_from_file, save_to_file

openai.api_key = os.getenv("OPENAI_API_KEY")


def load_names(fpath):
    """
    Load names of known objects in given environment.
    Assume 1 name per line in txt file, e.g. data/osm/osm_landmarks_corlw.txt
    Assume 1 dictionary of key: landmark name, value: semantic info in json file, e.g. data/osm/lmks/boston.json
    """
    ftype = os.path.splitext(fpath)[-1][1:]
    if ftype == "txt":
        with open(fpath, 'r') as rf:
            names = [line.strip() for line in rf.readlines()]
    else:
        raise ValueError(f"ERROR: file type {ftype} not recognized")
    return names


def store_embeds(model, env_dpath, lmk_fpath, keep_keys, gpt3_embed_engine=None):
    lmk2sem = load_from_file(lmk_fpath)

    if model == "gpt3":
        ground_module = GPT3(gpt3_embed_engine)
    # elif model == 'bert':
    #     ground_module = BERT()
    else:
        raise ValueError("ERROR: grounding module not recognized")

    name2embed = {}
    for lmk, sem in lmk2sem.items():
        sem_filtered = {"name": lmk}
        if keep_keys:
            sem_filtered.update({k: v for k, v in sem.items() if k in keep_keys})
        name2embed[lmk] = ground_module.get_embedding(json.dumps(sem_filtered))

    embed_dpath = os.path.join(env_dpath, "lmk_sem_embeds")
    os.makedirs(embed_dpath, exist_ok=True)
    lmk_fname = Path(lmk_fpath).stem
    if model == "gpt3":
        save_fpath = os.path.join(embed_dpath, f"obj2embed_{lmk_fname}_{gpt3_embed_engine}.pkl")
    else:
        save_fpath = os.path.join(embed_dpath, f"obj2embed_{lmk_fname}_{model}.pkl")
    save_to_file(name2embed, save_fpath)
    return save_fpath


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--env", type=str, default="cleanup", choices=["osm", "cleanup"], help="fpath or dpath to lmks.")
    parser.add_argument("--model", type=str, default="gpt3", choices=["gpt3", "bert"])
    parser.add_argument("--gpt3_embed_engine", type=str, default="text-embedding-ada-002")
    args = parser.parse_args()

    env_dpath = os.path.join("data", args.env)
    lmk_dpath = os.path.join(env_dpath, "lmks")
    lmk_fpaths = [os.path.join(lmk_dpath, fname) for fname in os.listdir(lmk_dpath) if "json" in fname]

    keep_keys = [
        "amenity", "shop", "addr:street",
        "short_name", "building", "building:part" "leisure", "tourism", "historic",
        "healthcare", "area", "landuse", "waterway", "aeroway", "highway", "office", "operator", "brand", "branch",
        "cuisine", "beauty", "official_name", "alt_name", "station", "railway", "subway",
    ] if args.env == "osm" else []
    for idx, lmk_fpath in enumerate(lmk_fpaths):
        print(f"generating landmark embedding for {lmk_fpath}")
        save_fpath = store_embeds(args.model, env_dpath, lmk_fpath, keep_keys, args.gpt3_embed_engine)
        print(f"{idx}: embeddings generated by model: {args.model}\nstored at: {save_fpath}\n")
